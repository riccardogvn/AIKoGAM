{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac63d98-27b0-402c-bb5d-12ed43a9e832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#RUN THIS CELL ONLY ONCE\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87f1ddb-7750-4a91-a2a9-c12cf9ea795a",
   "metadata": {
    "id": "b87f1ddb-7750-4a91-a2a9-c12cf9ea795a"
   },
   "source": [
    "<h1>AIKoGAM: An AI-driven Knowledge Graph of the Antiquities market: toward automatised methods to identify illicit trafficking networks</h1>\n",
    "<p>This notebook enables to replicate the methods described in: Giovanelli, R.,Traviglia, A., 2023. <i>AIKoGAM: An AI-driven Knowledge Graph of the Antiquities market: toward automatised methods to identify illicit trafficking networks</i>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e61940-a82a-4c73-8671-0f1002202938",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1131,
     "status": "ok",
     "timestamp": 1690971906503,
     "user": {
      "displayName": "Riccardo GIOVANELLI",
      "userId": "03825328568373642960"
     },
     "user_tz": -120
    },
    "id": "cuRpCtxW6X8m",
    "outputId": "a48a4bf9-9de8-418d-b1da-7027e201edd7"
   },
   "source": [
    "<h2>Web Harvesting</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515f948-c87e-4edc-98ea-0bbc0afba476",
   "metadata": {
    "editable": true,
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1690971914383,
     "user": {
      "displayName": "Riccardo GIOVANELLI",
      "userId": "03825328568373642960"
     },
     "user_tz": -120
    },
    "id": "a515f948-c87e-4edc-98ea-0bbc0afba476",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import the libraries that will be used\n",
    "import spacy\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import requests\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from src.utils.utils import *\n",
    "from src.db.db_connection import *\n",
    "from setup import config\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from html import unescape\n",
    "from typing import Dict, Any\n",
    "from event_extraction import *\n",
    "from kg_construction import *\n",
    "ner_model = spacy.load(\"en_core_web_md\")\n",
    "now = datetime.now()\n",
    "date_and_hour = datetime.now().strftime(\"%d%m%Y_%H%M\")\n",
    "nlp = spacy.load('en_core_web_md') #load the spacy library for Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb9b805-a23b-4170-89aa-a6796c2a2563",
   "metadata": {
    "editable": true,
    "id": "2cb9b805-a23b-4170-89aa-a6796c2a2563",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h3>Christie's WA</h3>\n",
    "In the input, insert the first year from wich to start the collection, and the last year. Before 1998 there are no data.</br>\n",
    "Chose if you want to store images. The images will be stored in a subfolder of a new \"images\" folder inside the project.</br>\n",
    "The estimated time for storing data of a sale with around 80 objects and no images is 59 sec on a CPU.</br></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985ba0b-2472-4dfc-a4b5-a72d200b6426",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "executionInfo": {
     "elapsed": 261044,
     "status": "ok",
     "timestamp": 1690968698844,
     "user": {
      "displayName": "Riccardo GIOVANELLI",
      "userId": "03825328568373642960"
     },
     "user_tz": -120
    },
    "id": "3985ba0b-2472-4dfc-a4b5-a72d200b6426",
    "outputId": "40c135d6-948a-42eb-a3eb-c6dc2d531a4a",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_year = int(input(\"Please, input the year from which to start scraping\"))\n",
    "end_year = int(input(\"Please, input the last year from which you want to scrape\")) + 1\n",
    "storingImage_christies = input(\"Do you want to store images? Y or N\").lower()\n",
    "if storingImage_christies == 'y':\n",
    "    antiquities = collect_sales(start_year, end_year, log_file='data_collection.log', storeImage=True)\n",
    "else:\n",
    "    antiquities = collect_sales(start_year, end_year, log_file='data_collection.log', storeImage=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b422cc-9b0c-476f-8c9d-ca287932bbb7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 717,
     "status": "ok",
     "timestamp": 1690964639105,
     "user": {
      "displayName": "Riccardo GIOVANELLI",
      "userId": "03825328568373642960"
     },
     "user_tz": -120
    },
    "id": "68b422cc-9b0c-476f-8c9d-ca287932bbb7",
    "outputId": "8d0c284a-9464-46f7-908d-15f335d8bac8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "antiquities[0] #run this cell if you want to have a look on the structure of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1e625-7929-4c39-b4e9-1fba00614df0",
   "metadata": {
    "id": "8bd1e625-7929-4c39-b4e9-1fba00614df0"
   },
   "source": [
    "<h3>Sotheby's WA</h3>\n",
    "<p>Chose if you want to store images. The images will be stored in a subfolder of a new \"images\" folder inside the project.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5014d86b-1372-4937-90ca-28c3e5319f72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231372,
     "status": "ok",
     "timestamp": 1690964949391,
     "user": {
      "displayName": "Riccardo GIOVANELLI",
      "userId": "03825328568373642960"
     },
     "user_tz": -120
    },
    "id": "5014d86b-1372-4937-90ca-28c3e5319f72",
    "outputId": "97cfefbb-becb-4daf-ead9-0dc9b332a91c"
   },
   "outputs": [],
   "source": [
    "with open('auctionIds_sotheby.json','r',encoding='utf-8') as file:\n",
    "    auctionIds_sotheby = json.load(file)\n",
    "auctionIds_sotheby = auctionIds_sotheby[80:81]\n",
    "storingImage_sothebys = input(\"Do you want to store images? Y or N\").lower()\n",
    "if storingImage_sothebys == 'y':\n",
    "    antiquities_sothebys = collect_sales_sothebys(auctionIds_sotheby, storeImage=True)\n",
    "else:\n",
    "    antiquities_sothebys = collect_sales_sothebys(auctionIds_sotheby, storeImage=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6431098f-f168-46f4-b756-a1dda30f3ad4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1673,
     "status": "ok",
     "timestamp": 1690964951053,
     "user": {
      "displayName": "Riccardo GIOVANELLI",
      "userId": "03825328568373642960"
     },
     "user_tz": -120
    },
    "id": "6431098f-f168-46f4-b756-a1dda30f3ad4",
    "outputId": "c9d615da-dadf-4d40-c393-96bdde8a1d15",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "antiquities_sothebys[0] #run this cell if you want to have a look on the structure of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c9edf-cacd-4253-bc56-6d521107686e",
   "metadata": {
    "id": "ee8c9edf-cacd-4253-bc56-6d521107686e"
   },
   "source": [
    "<h3>Phoenix Ancient Art's WA</h3>\n",
    "<p>Chose if you want to store images. The images will be stored in a subfolder of a new \"images\" folder inside the project.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349a0f7a-81bd-4830-bc6c-c5809f612550",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 654349,
     "status": "ok",
     "timestamp": 1690965605398,
     "user": {
      "displayName": "Riccardo GIOVANELLI",
      "userId": "03825328568373642960"
     },
     "user_tz": -120
    },
    "id": "349a0f7a-81bd-4830-bc6c-c5809f612550",
    "outputId": "3cea1431-81e3-4720-900e-9b3c17d94794"
   },
   "outputs": [],
   "source": [
    "storingImage_paa = input(\"Do you want to store images? Y or N\").lower()\n",
    "\n",
    "if storingImage_paa == 'y':\n",
    "    antiquities_paa = collectPAA(storeImage=True)\n",
    "else:\n",
    "    antiquities_paa = collectPAA(storeImage=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6bddfe-7d87-4dd0-b8ce-fba6a222c627",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1690965702727,
     "user": {
      "displayName": "Riccardo GIOVANELLI",
      "userId": "03825328568373642960"
     },
     "user_tz": -120
    },
    "id": "2e6bddfe-7d87-4dd0-b8ce-fba6a222c627",
    "outputId": "db483349-fe23-4e20-e28d-dc632bea3184"
   },
   "outputs": [],
   "source": [
    "antiquities_paa[0] #run this cell if you want to have a look on the structure of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d281ce78-2c20-400b-8ee2-5020039a1da7",
   "metadata": {
    "id": "d281ce78-2c20-400b-8ee2-5020039a1da7"
   },
   "source": [
    "<h2>Ontology mapping and Knowledge Graph database building</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0faa82-a7d7-4610-a847-2931bc7eef5e",
   "metadata": {},
   "source": [
    "<h3>Ontology mapping</h3>\n",
    "<p>The following cell will reload the datasets you stored from the previous cells and remap the datasets toward a single cleaned and postprocessed datasets, with only the relevant key-values pairs and a common taxonomy</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14304dd1-1d5f-4fd7-8297-e970091992d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "1f68be24f16f43198f50f7cc59950642",
      "9e00d42a6a044326bd496c21e0f1974a",
      "be803edef69b4aa7adfa595dd026aa73",
      "e135d04476584e3aa73cf026434573f2",
      "bf0a1397a0f74c019e3b53b803627316",
      "cf2efc07eb234305a835e8a746232b72",
      "976bcaa193f84fd4bbba3e4c1b4672fc",
      "c933ac28324e4133bc1b5e02460b5625",
      "29b4ec4259d3482b851c0cffa4ab9069",
      "729c6adc6baf4022a05d9619b6daa0c0",
      "8e9149e073534b2b98fd2dcea8fc3ba0"
     ]
    },
    "executionInfo": {
     "elapsed": 1214,
     "status": "ok",
     "timestamp": 1690971919259,
     "user": {
      "displayName": "Riccardo GIOVANELLI",
      "userId": "03825328568373642960"
     },
     "user_tz": -120
    },
    "id": "14304dd1-1d5f-4fd7-8297-e970091992d1",
    "outputId": "cad672ad-056c-40e0-e56d-999d61c4be50",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(r'christies_raw.json','r',encoding='utf-8') as f:\n",
    "    christies_data = json.load(f)\n",
    "with open(r'sothebys_raw.json','r',encoding='utf-8') as f2:\n",
    "    sothebys_data = json.load(f2)\n",
    "with open(r'paa_raw.json','r',encoding='utf-8') as f3:\n",
    "    paa_data = json.load(f3)\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='error_log.log', level=logging.ERROR,format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# Map Christie's data to the final keys\n",
    "final_christies_data = remap_christies_data(christies_data)\n",
    "# Map Sotheby's data to the final keys\n",
    "final_sothebys_data = map_sothebys_data(sothebys_data)\n",
    "# Map PAA's data to the final keys\n",
    "final_paa_data = remap_paa_data(paa_data)\n",
    "# Combine datasets into a single list\n",
    "final_output = final_sothebys_data + final_christies_data + final_paa_data\n",
    "# Hash and Reorder json file\n",
    "db = hashAndClean(final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e765cdf9-22ed-4857-91a6-5946363b4aad",
   "metadata": {},
   "source": [
    "The following cell will save in a .json file inside datasets folder the complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fd6fe1-758f-4111-a150-440c766412cf",
   "metadata": {
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1690971975477,
     "user": {
      "displayName": "Riccardo GIOVANELLI",
      "userId": "03825328568373642960"
     },
     "user_tz": -120
    },
    "id": "f8fd6fe1-758f-4111-a150-440c766412cf"
   },
   "outputs": [],
   "source": [
    "os.makedirs('datasets', exist_ok=True)\n",
    "with open(r'datasets/db.json','w') as file:\n",
    "  json.dump(db,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c392c1f-eed4-4ae4-8a9b-7428f5ef9ef7",
   "metadata": {},
   "source": [
    "The following cell will reload the completa data file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164550fc-8757-42b6-a202-578026967fe6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h3>Knowledge Graph database building</h3>\n",
    "The following cells will generate a Neo4j Knowledge Graph from the .json dataset, extracting events from the provenance statements as collected and refactoring them into separate entities such as actors, dates, locations.</br>\n",
    "Before running the following cells make sure to follow the Neo4j installation guidelines.</br>\n",
    "<p>\n",
    "<b>Neo4j Installation and setup</b></br>\n",
    "Install Neo4J Desktop from <a href='https://neo4j.com/deployment-center/'> here </a> chosing the right os.</br>\n",
    "<img src=\"imgs/n4jdsk.png\" width='630'> </br>\n",
    "Follow along the guide from Neo4j documentation <a href='https://neo4j.com/docs/desktop-manual/current/'>here</a>.</br>\n",
    "When you first database is created, as described <a href='https://neo4j.com/docs/desktop-manual/current/operations/create-dbms/'>here</a>, you will need to adjust the configuration inside the <a href='setup/config.py'>config.py</a> file under 'setup' folder in this project, changing the uri and the password according to your Neo4j Desktop configurations. The default localhost and username are the following, the password is set by you upon creating your first database instance.\n",
    "\n",
    "</p>\n",
    "<p>\n",
    "neo4j = {</br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;\"uri\":\"bolt://localhost:7687\",</br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;\"username\": \"neo4j\",</br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;\"password\": \"admininstrator\",</br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;\"encrypted\": False</br>\n",
    "}</br>\n",
    "</p>\n",
    "<p>When both Neo4j Desktop and the config file are set, click \"Start\" to start the Neo4j Database instance and then \"Open\".</p>\n",
    "<p><img src='imgs/kgopen.png' width='630'></p>\n",
    "<p></p>\n",
    "<p><img src='imgs/kgstart.png' width='630'></p>\n",
    "<p>This will open in a new window an empty database.</br>\n",
    "<img src='imgs/newdb.png' width = '630'></br>\n",
    "Making sure our database is <b>active</b>, we can procede and run the following cells.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f69df2-0661-4e86-84e3-40d10e1ed0f1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The following event_extraction.py analyses and splits each provenance statement found in the raw data into different <i>events</i>. Each event ideally contains an actor, a location, and a time-span indication.\n",
    "For testing, we utilise the NER model 'en-core-web-md' from Spacy library. The output 'events/events.txt' will contain for each artwork the labeled entities found in each separated provenance event. </br>\n",
    "The estimated time for extracting events from 39103 objects is 64 minutes on a CPU (nearly 10 objects/s)</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Igds4Jn7zLk3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "executionInfo": {
     "elapsed": 10666,
     "status": "ok",
     "timestamp": 1690975699694,
     "user": {
      "displayName": "Riccardo GIOVANELLI",
      "userId": "03825328568373642960"
     },
     "user_tz": -120
    },
    "id": "Igds4Jn7zLk3",
    "outputId": "fd8a6ffa-035d-4c6e-815c-7d54780094e1",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from event_extraction import *\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Named Entity Recognition (NER) model\n",
    "    ner_model = spacy.load(\"en_core_web_md\")\n",
    "    \n",
    "    file = 'datasets/db.json'\n",
    "\n",
    "    artwork_index = 0\n",
    "    artwork_index = extract_store_events(ner_model, file, artwork_index)\n",
    "    \n",
    "        \n",
    "    print(\"Job done\")        \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cacbc11-151b-43c7-bce1-d2c3240bc55b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The following code will populate the Neo4j database with the original nodes of artworks and events connected to the corresponding artworks through a (a:artwork)-[r:PARTICIPATED_TO_EVENT]->(b:event) relationship.</br>\n",
    "In this way, each event involving a specific object is automatically linked to the respective entities represented within it.</br>\n",
    "Autonomous CYPHER queries refactor the events according to the ontology schema: the event node remains central, receiving relationships from the artworks and projecting or receiving new relationships to other entities automatically generated by Spacy and refactored based on our ontology.</br>\n",
    "The estimated time for building and refactoring the Neo4j KG Database is  minutes on a CPU.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f8a48-d08c-4d30-846c-dc5491fe0222",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "__name__ = \"__main__\"\n",
    "import kg_construction\n",
    "from kg_construction import *\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39c2f21-fdcf-4f1d-8d90-4c7721323ec6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h2>Preliminary Results</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38786a01-7bf8-46e5-84ea-12f7d5380642",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generalQuery(query):\n",
    "    from neo4j import GraphDatabase\n",
    "    driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"administrator\"), encrypted=False)\n",
    "    tx = driver.session().begin_transaction()\n",
    "    result = tx.run(query)\n",
    "    records = []\n",
    "    for record in result:\n",
    "        records.append(record)\n",
    "\n",
    "    \n",
    "    print(query)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e70e3-64e8-403f-a3a7-835bba620c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b148831-d9b4-4d66-9f66-1b9b8aa6fe4a",
   "metadata": {},
   "source": [
    "<h3>First Projection: from Knowledge Graph to bipartite Graph</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a88cc1-8113-48f9-9104-ad3cadf683e0",
   "metadata": {},
   "source": [
    "With the following cell we connect to our Neo4j database and collect artwor, events and actors nodes with their relationsip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b033d-2174-4851-97b8-f7c29aede262",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "query = \"MATCH (n:artwork)-[r]-(e:event)-[r2]-(a:actor) RETURN *\"\n",
    "result = generalQuery(query)\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "for record in tqdm(result):\n",
    "    artwork_node = record[\"n\"]\n",
    "    event_node = record[\"e\"]\n",
    "    actor_node = record[\"a\"]\n",
    "    relationship_1 = record[\"r\"]\n",
    "    relationship_2 = record[\"r2\"]\n",
    "\n",
    "    # Add nodes and edges to the NetworkX graph\n",
    "    G.add_node(artwork_node.id, label='artwork', properties=artwork_node._properties)    \n",
    "    G.add_node(event_node.id, label=\"event\", properties=event_node._properties)\n",
    "    G.add_node(actor_node.id, label=\"actor\", properties=actor_node._properties)\n",
    "    G.add_edge(artwork_node.id, event_node.id, label=relationship_1.type, direction='forward')\n",
    "    G.add_edge(event_node.id, actor_node.id, label=relationship_2.type, direction='reverse')\n",
    "\n",
    "print(\"Node count:\", G.number_of_nodes())\n",
    "print(\"Edge count:\", G.number_of_edges())\n",
    "\n",
    "os.makedirs('graphs', exist_ok=True)\n",
    "# save graph object to file\n",
    "pickle.dump(G, open('graphs/graph.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac324bf9-15ba-4259-8f53-2e04f8812783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load graph object from file\n",
    "G = pickle.load(open('graphs/graph.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02c32f-0658-407e-9732-d894a8fac0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refactoring(string, graph):\n",
    "    old_actors_nodes = set()\n",
    "    \n",
    "    # Identify actor nodes with 'Sotheby's' in their name\n",
    "    for node in tqdm(subgraph.nodes(), desc=f\"Identifying {string.capitalize()} nodes\"):\n",
    "        if graph.nodes[node]['label'] == 'actor':\n",
    "            name = graph.nodes[node]['properties']['name']\n",
    "            if string in name.lower():\n",
    "                old_actors_nodes.add(node)\n",
    "    \n",
    "    # Create the super node and update relationships\n",
    "    # Update relationships for super node\n",
    "    if old_actors_nodes:\n",
    "        for actor in tqdm(old_actors_nodes, desc=f'Updating relationships for {string.capitalize()}'):\n",
    "            neighbors = list(graph.neighbors(actor))\n",
    "            for neighbor in neighbors:\n",
    "                edges = graph.edges(actor, neighbor)\n",
    "                for edge in edges:\n",
    "                    graph.add_edge(string.capitalize(), neighbor, attr_dict=edge[2])\n",
    "        \n",
    "        graph.add_edges_from(edges_to_add)\n",
    "        graph.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    return graph\n",
    "\n",
    "def newNodeId(subgraph):\n",
    "    all_ids = {node for node in subgraph.nodes() if isinstance(node, int)}\n",
    "    new_node_id = str(min(set(range(1, max(all_ids) + 2)) - all_ids))\n",
    "    return new_node_id\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "def normalize_name(name):\n",
    "    return unidecode(name.lower())\n",
    "\n",
    "def merge_nodes_with_name(graph, name):\n",
    "    normalized_name = normalize_name(name)\n",
    "    nodes_to_merge = [node for node in graph.nodes() if graph.nodes[node]['label'] == 'actor' and normalized_name in normalize_name(graph.nodes[node]['properties']['name']) and node != name]\n",
    "    \n",
    "    if nodes_to_merge:\n",
    "        merged_node_id = name\n",
    "        graph.add_node(merged_node_id, label='actor', properties={'name': merged_node_id})\n",
    "        \n",
    "        for node in nodes_to_merge:\n",
    "            neighbors = list(graph.neighbors(node))\n",
    "            for neighbor in neighbors:\n",
    "                if graph.nodes[neighbor]['label'] == 'artwork':\n",
    "                    graph.add_edge(merged_node_id, neighbor, label='dealt_with', direction='forward')\n",
    "            graph.remove_node(node)\n",
    "\n",
    "    \n",
    "    \n",
    "    return graph\n",
    "\n",
    "def normalize_name(name):\n",
    "    \"\"\"\n",
    "    Normalize a name by converting it to lowercase and removing Unicode characters.\n",
    "    \n",
    "    Parameters:\n",
    "    name (str): The input name to be normalized.\n",
    "    \n",
    "    Returns:\n",
    "    str: The normalized name.\n",
    "    \"\"\"\n",
    "    return unidecode(name.lower())\n",
    "\n",
    "def generate_ngrams(string, n):\n",
    "    \"\"\"\n",
    "    Generate n-grams of length n from a given string.\n",
    "    \n",
    "    Parameters:\n",
    "    string (str): The input string from which n-grams will be generated.\n",
    "    n (int): The length of each n-gram.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of n-grams.\n",
    "    \"\"\"\n",
    "    return [string[i:i + n] for i in range(len(string) - n + 1)]\n",
    "\n",
    "def build_ngram_index(strings, n=3):\n",
    "    \"\"\"\n",
    "    Build an n-gram index for a list of strings.\n",
    "    Each n-gram maps to a list of strings containing that n-gram.\n",
    "    \n",
    "    Parameters:\n",
    "    strings (list): List of strings to build the n-gram index from.\n",
    "    n (int): The length of each n-gram.\n",
    "    \n",
    "    Returns:\n",
    "    defaultdict: A defaultdict containing the n-gram index.\n",
    "    \"\"\"\n",
    "    ngram_index = defaultdict(list)\n",
    "    for string in strings:\n",
    "        ngrams = generate_ngrams(string, n)\n",
    "        for ngram in ngrams:\n",
    "            ngram_index[ngram].append(string)\n",
    "    return ngram_index\n",
    "\n",
    "def exception_append(shorter_string, merges, ngram_index):\n",
    "    \"\"\"\n",
    "    Append a string to the list of merges if it doesn't meet any exception criteria.\n",
    "    Also, check if the string's n-grams match with any existing strings using the n-gram index.\n",
    "    \n",
    "    Parameters:\n",
    "    shorter_string (str): The string to be added to the merges list.\n",
    "    merges (list): The list of merged strings.\n",
    "    ngram_index (defaultdict): The n-gram index built from build_ngram_index function.\n",
    "    \n",
    "    Returns:\n",
    "    list: The updated merges list.\n",
    "    \"\"\"\n",
    "    if shorter_string in merges or shorter_string.lower() in exceptionsin or shorter_string.lower() in exceptionsequals:\n",
    "        return merges\n",
    "    # Check if any of the n-grams of the new string are present in the n-gram index\n",
    "    ngrams = generate_ngrams(shorter_string, 3)  # Using 3-grams for comparison\n",
    "    for ngram in ngrams:\n",
    "        if ngram in ngram_index:\n",
    "            print(f\"Similarity found for '{shorter_string}': {ngram_index[ngram]}\")\n",
    "            break\n",
    "    merges.append(shorter_string)\n",
    "    print(f\"Added to merges: {shorter_string}\")\n",
    "    return merges\n",
    "\n",
    "def find_similar_nodes(graph, merges, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Find nodes with similar names in the graph and update the list of merges accordingly.\n",
    "    Also, utilize the n-gram index to identify similar strings.\n",
    "    \n",
    "    Parameters:\n",
    "    graph (NetworkX Graph): The graph containing nodes to compare.\n",
    "    merges (list): The list of merged strings.\n",
    "    threshold (float, optional): The similarity threshold for node comparison.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the list of similar nodes and the updated merges list.\n",
    "    \"\"\"\n",
    "    similar_nodes = []\n",
    "    ngram_index = build_ngram_index(merges)\n",
    "\n",
    "    for node1 in tqdm(graph.nodes(), desc='Calculating similarity'):\n",
    "        if graph.nodes[node1]['label'] == 'actor':\n",
    "            name1 = graph.nodes[node1]['properties']['name']\n",
    "            normalized_name1 = normalize_name(name1)\n",
    "\n",
    "            for node2 in graph.nodes():\n",
    "                if node1 != node2 and graph.nodes[node2]['label'] == 'actor':\n",
    "                    name2 = graph.nodes[node2]['properties']['name']\n",
    "                    normalized_name2 = normalize_name(name2)\n",
    "                    \n",
    "\n",
    "                    if normalized_name2 == normalized_name1:\n",
    "                        shorter_string = normalized_name1 if len(normalized_name1) < len(normalized_name2) else normalized_name2\n",
    "                        shorter_string = shorter_string.title()\n",
    "                        merges = exception_append(shorter_string, merges, ngram_index)\n",
    "                    else:\n",
    "                        similarity = fuzz.ratio(normalized_name1, normalized_name2) / 100\n",
    "                        if similarity >= threshold:\n",
    "                            similar_nodes.append((node1, node2, similarity))\n",
    "                            similarity = round(similarity, 2)\n",
    "                            if similarity == 1.00:\n",
    "                                shorter_string = normalized_name1 if len(normalized_name1) < len(normalized_name2) else normalized_name2\n",
    "                                shorter_string = shorter_string.title()\n",
    "                                merges = exception_append(shorter_string, merges, ngram_index)\n",
    "\n",
    "    return similar_nodes, merges\n",
    "\n",
    "def delete_nodes_by_name(graph, target_name):\n",
    "    nodes_to_delete = [node for node in graph.nodes() if graph.nodes[node]['label'] == 'actor' and graph.nodes[node]['properties']['name'] == target_name]\n",
    "    for node in nodes_to_delete:\n",
    "        graph.remove_node(node)\n",
    "    print(\"Node count:\", graph.number_of_nodes())\n",
    "    print(\"Edge count:\", graph.number_of_edges())\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b4399-c7e2-4167-b47a-a0e6d32c42dd",
   "metadata": {},
   "source": [
    "Once we collected the nodes that we need to perform the refactoring, we actually refactor our graph transforming each event to which both an artwork and a actor participated into a directed relationship (actor)-[:DEALT_WITH]->(artwork).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e64ac2d-a6e3-4fcb-bf40-8a3f133c1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original graph\n",
    "subgraph = G.copy()\n",
    "\n",
    "# List to store nodes to be removed\n",
    "nodes_to_remove = []\n",
    "\n",
    "# Identify and remove event nodes\n",
    "for node in tqdm(list(subgraph.nodes()), desc='Refactoring artwork-[]-event-[]-actors -> artwork-[]-actors'):\n",
    "    if subgraph.nodes[node]['label'] == 'event':\n",
    "        # Find connected actor and artwork nodes\n",
    "        neighbors = list(subgraph.neighbors(node))\n",
    "        actor_nodes = [n for n in neighbors if subgraph.nodes[n]['label'] == 'actor']\n",
    "        artwork_nodes = [n for n in neighbors if subgraph.nodes[n]['label'] == 'artwork']\n",
    "        \n",
    "        # Add the actor-artwork relationships\n",
    "        for actor in actor_nodes:\n",
    "            for artwork in artwork_nodes:\n",
    "                subgraph.add_edge(actor, artwork, label='dealt_with', direction='forward')\n",
    "        \n",
    "        # Add the event node to nodes_to_remove list\n",
    "        nodes_to_remove.append(node)\n",
    "\n",
    "# Remove the nodes\n",
    "subgraph.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "print(\"Node count:\", subgraph.number_of_nodes())\n",
    "print(\"Edge count:\", subgraph.number_of_edges())\n",
    "\n",
    "# Set titles for remaining nodes\n",
    "for node in tqdm(subgraph.nodes(), desc='Setting titles'):\n",
    "    if subgraph.nodes[node]['label'] == 'actor':\n",
    "        name = subgraph.nodes[node]['properties']['name']\n",
    "        subgraph.nodes[node]['title'] = f\"Actor: {name} (ID: {node})\"\n",
    "    elif subgraph.nodes[node]['label'] == 'artwork':\n",
    "        lotTitle = subgraph.nodes[node]['properties']['lotTitle']\n",
    "        subgraph.nodes[node]['title'] = f\"Artwork: {lotTitle} (ID: {node})\"\n",
    "        \n",
    "# Select a subset of nodes for visualization\n",
    "subset_nodes = list(subgraph.nodes())[:200]  # Change the number of nodes as needed\n",
    "subgraph_subset = subgraph.subgraph(subset_nodes)\n",
    "\n",
    "# Create a Network instance\n",
    "nt = Network(notebook=True)\n",
    "nt.from_nx(subgraph_subset)\n",
    "\n",
    "# Display the interactive visualization\n",
    "nt.show('graph_subset.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bccc706-87fa-4697-bbab-de5aee8a3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "from unidecode import unidecode\n",
    "merges = [\"Sotheby's\",\"Christie's\",\"Junkunc\",\"the Tuyet Nguyet\",\"Koutoulakis\",\"Hotel Drouot\",\"Henry H Arnhold\",\"Alan Steele\",\"Groppi Collection\",\"Empain\",\"Jon Edwards\"]\n",
    "# Set of strings that should be considered exceptions\n",
    "exceptionsequals = {'house', 'sa', 'collection', 'antiquites', 'archeologie', 'un', 'inc'}\n",
    "exceptionsin = {'private collection', 'collection privee', 'the estate of the late', 'collection particuliere', 'private european collection', 'property of a new york city collection', 'property from an important american collection','royal'}\n",
    "\n",
    "# Example usage\n",
    "similar_nodes, merges = find_similar_nodes(subgraph, merges, threshold=0.8)\n",
    "for node1, node2, similarity in similar_nodes:\n",
    "    print(f\"Nodes {node1} and {node2} are similar with similarity {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c58da-acb1-4c7a-8085-3b378222420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactor nodes for 'Sotheby's' and 'Christie's\n",
    "#subgraph.nodes[114940]['properties']['name'] = subgraph.nodes[114939]['properties']['name']\n",
    "#merges = [\"Sotheby's\",\"Christie's\",\"Junkunc\",\"the Tuyet Nguyet\",\"Koutoulakis\",\"Hotel Drouot\",\"Henry H Arnhold\",\"Alan Steele\",\"Groppi Collection\",\"Empain\",\"Jon Edwards\"]\n",
    "for x in merges:\n",
    "    merge_nodes_with_name(subgraph,x)\n",
    "\n",
    "print(\"Node count:\", subgraph.number_of_nodes())\n",
    "print(\"Edge count:\", subgraph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df95ae-919f-4044-b3a5-3f78b8c05de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set titles for remaining nodes\n",
    "for node in tqdm(subgraph.nodes(), desc='Setting titles'):\n",
    "    if subgraph.nodes[node]['label'] == 'actor':\n",
    "        name = subgraph.nodes[node]['properties']['name']\n",
    "        subgraph.nodes[node]['title'] = f\"Actor: {name} (ID: {node})\"\n",
    "    elif subgraph.nodes[node]['label'] == 'artwork':\n",
    "        lotTitle = subgraph.nodes[node]['properties']['lotTitle']\n",
    "        subgraph.nodes[node]['title'] = f\"Artwork: {lotTitle} (ID: {node})\"\n",
    "        \n",
    "import random\n",
    "\n",
    "# Choose a random starting node\n",
    "starting_node = random.choice(list(subgraph.nodes()))\n",
    "print(starting_node)\n",
    "\n",
    "# Perform a breadth-first search to collect connected nodes\n",
    "def get_connected_nodes(graph, starting_node, num_nodes):\n",
    "    connected_nodes = set()\n",
    "    queue = [starting_node]\n",
    "    \n",
    "    while queue and len(connected_nodes) < num_nodes:\n",
    "        current_node = queue.pop(0)\n",
    "        connected_nodes.add(current_node)\n",
    "        neighbors = list(graph.neighbors(current_node))\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor not in connected_nodes:\n",
    "                queue.append(neighbor)\n",
    "    \n",
    "    return connected_nodes\n",
    "\n",
    "# Choose a random starting node\n",
    "starting_node = random.choice(list(subgraph.nodes()))\n",
    "print(starting_node)\n",
    "\n",
    "# Choose the number of nodes to visualize\n",
    "num_nodes_to_visualize = 50\n",
    "\n",
    "# Get the subset of connected nodes\n",
    "connected_nodes_subset = get_connected_nodes(subgraph, starting_node, num_nodes_to_visualize)\n",
    "subgraph_connected_subset = subgraph.subgraph(connected_nodes_subset)\n",
    "\n",
    "# Create a Network instance\n",
    "nt_connected = Network(notebook=True)\n",
    "nt_connected.from_nx(subgraph_connected_subset)\n",
    "\n",
    "# Display the interactive visualization\n",
    "nt_connected.show('graph_connected_subset.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec03aac-2bf6-43a2-a789-7769f622cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Calculate total degree for each actor node\n",
    "actor_degrees = {node: subgraph.degree(node) for node in subgraph.nodes() if subgraph.nodes[node]['label'] == 'actor'}\n",
    "\n",
    "# Sort nodes by total degree in descending order\n",
    "sorted_nodes = sorted(actor_degrees, key=actor_degrees.get, reverse=True)\n",
    "\n",
    "# Choose the top 28 nodes (actors with highest total degree)\n",
    "top_nodes = sorted_nodes[:28]\n",
    "for node in top_nodes:\n",
    "    print(node)\n",
    "    \n",
    "\n",
    "# Get names and total degree values for the top nodes\n",
    "node_names = [subgraph.nodes[node]['properties']['name'] for node in top_nodes]\n",
    "node_total_degrees = [actor_degrees[node] for node in top_nodes]\n",
    "\n",
    "# Create a bar plot with logarithmic scale\n",
    "plt.figure(figsize=(20, 7))  # Adjust the figure size for a 2:1 ratio\n",
    "bars = plt.barh(node_names, node_total_degrees, color='lightcoral')  # Use a light coral color\n",
    "plt.xscale('log')  # Set x-axis to logarithmic scale\n",
    "plt.xlabel('Total Degree (log scale)')\n",
    "plt.ylabel('Actor Name')\n",
    "plt.title('Top 28 Actors based on Total Degree')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the highest degree at the top\n",
    "\n",
    "# Display total degree values inside the bars\n",
    "for i, bar in enumerate(bars):\n",
    "    plt.text(bar.get_width() +20, bar.get_y() + bar.get_height()/2, f'{node_total_degrees[i]}', va='center')\n",
    "# Adjust margins to prevent text from going outside the figure boundary\n",
    "plt.subplots_adjust(left=0.2, right=15)\n",
    "\n",
    "# Create 'plots' directory if it doesn't exist\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "plt.tight_layout()  # Adjust layout for better appearance\n",
    "plt.savefig('plots/total_degree_plot.png', dpi=300, bbox_inches='tight')  # Save the plot to a file\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29140a6-ad7b-4505-9581-ab83fd895626",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h3>Second Projection: from bipartite to a one-mode undirected weighted graph (actors)-[:SHARES_ARTWORK]-(actors)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41987d9d-4f3b-43c0-8264-05f2a462a40e",
   "metadata": {},
   "source": [
    "The following cell will operate the projection directly in python, but it takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b671b314-f3ea-48f2-8cb4-8d665e823fb6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm\n",
    "import community\n",
    "import networkx as nx\n",
    "\n",
    "# Create a new directed graph to hold the adjusted edges\n",
    "adjusted_graph = nx.DiGraph()\n",
    "# Sort nodes by degree in descending order\n",
    "sorted_nodes = sorted(subgraph.nodes(), key=lambda x: subgraph.degree(x), reverse=True)\n",
    "\n",
    "# Create a new undirected subgraph for actor sharing artwork\n",
    "shared_artwork_subgraph = nx.Graph()\n",
    "\n",
    "# Create a subgraph excluding the highest degree nodes \"Christie's\" and \"Sotheby's\"\n",
    "subgraph_excluded = subgraph.subgraph(sorted_nodes[2:])\n",
    "# Iterate through the 'actor' nodes in the original subgraph\n",
    "for actor in tqdm(subgraph_excluded.nodes(),desc='Processing nodes'):\n",
    "    if subgraph.nodes[actor]['label'] == 'actor':\n",
    "        # Get the 'artwork' neighbors of the current 'actor'\n",
    "        actor_neighbors = [neighbor for neighbor in subgraph_excluded.neighbors(actor) if subgraph_excluded.nodes[neighbor]['label'] == 'artwork']\n",
    "        # Create edges between the 'actor' and 'artwork' neighbors\n",
    "        for artwork in actor_neighbors:\n",
    "            shared_actors = [neighbor for neighbor in subgraph_excluded.neighbors(artwork) if neighbor != actor and subgraph_excluded.nodes[neighbor]['label'] == 'actor']\n",
    "            for shared_actor in shared_actors:\n",
    "                # Add the start node as 'actor' and the end node as 'actor' in the adjusted graph\n",
    "                adjusted_graph.add_node(actor, **subgraph_excluded.nodes[actor])\n",
    "                adjusted_graph.add_node(shared_actor, **subgraph_excluded.nodes[shared_actor])\n",
    "                # Add the edge between actors with weight based on the number of shared artworks\n",
    "                shared_artworks_count = len([neighbor for neighbor in subgraph_excluded.neighbors(artwork) if subgraph_excluded.nodes[neighbor]['label'] == 'actor'])\n",
    "                adjusted_graph.add_edge(actor, shared_actor, weight=shared_artworks_count)\n",
    "\n",
    "# Convert the directed graph to an undirected graph\n",
    "adjusted_graph = adjusted_graph.to_undirected()\n",
    "\n",
    "# Find all connected components in the undirected graph\n",
    "connected_components = list(nx.connected_components(adjusted_graph))\n",
    "\n",
    "# Find the largest connected component\n",
    "largest_connected_component = max(connected_components, key=len)\n",
    "print(len(largest_connected_component))\n",
    "\n",
    "# Create a subgraph containing only the largest connected component\n",
    "largest_subgraph = adjusted_graph.subgraph(largest_connected_component)\n",
    "adjusted_graph = largest_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c46888d-b6a7-4e0d-a7a8-8e256f807c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph, Node, Relationship\n",
    "import networkx as nx\n",
    "import threading\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Number of Nodes\n",
    "num_nodes = largest_subgraph.number_of_nodes()\n",
    "print(\"Number of Nodes:\", num_nodes)\n",
    "\n",
    "# Number of Relationships (edges)\n",
    "num_edges = largest_subgraph.number_of_edges()\n",
    "print(\"Number of Relationships:\", num_edges)\n",
    "\n",
    "# Average Degree\n",
    "avg_degree = sum(dict(largest_subgraph.degree()).values()) / num_nodes\n",
    "print(\"Average Degree (AD):\", avg_degree)\n",
    "\n",
    "\n",
    "# Create a lock to prevent concurrent access\n",
    "#lock = threading.Lock()\n",
    "\n",
    "\n",
    "def calculate_with_timeout(func, graph, timeout):\n",
    "    result = None\n",
    "\n",
    "    def calculation_thread():\n",
    "        nonlocal result\n",
    "        try:\n",
    "            result = func(graph)\n",
    "        except Exception as e:\n",
    "            result = \"Calculation error: \" + str(e)\n",
    "\n",
    "    thread = threading.Thread(target=calculation_thread)\n",
    "    thread.start()\n",
    "    thread.join(timeout)\n",
    "    \n",
    "    if thread.is_alive():\n",
    "        thread.join()  # Make sure the thread is terminated\n",
    "        result = \"Calculation took too long and was terminated.\"\n",
    "\n",
    "    return result\n",
    "'''\n",
    "# Calculate Average Path Length with timeout\n",
    "avg_path_length = calculate_with_timeout(nx.average_shortest_path_length, largest_subgraph, timeout=20)\n",
    "print(\"Average Path Length (L):\", avg_path_length)\n",
    "\n",
    "# Calculate Average Clustering Coefficient with timeout\n",
    "avg_clustering = calculate_with_timeout(nx.average_clustering, largest_subgraph, timeout=20)\n",
    "print(\"Average Clustering Coefficient (C):\", avg_clustering)\n",
    "\n",
    "# Calculate Graph Edge Density with timeout\n",
    "graph_density = calculate_with_timeout(nx.density, largest_subgraph, timeout=20)\n",
    "print(\"Graph Edge Density (Dns):\", graph_density)\n",
    "\n",
    "# Calculate Graph Diameter with timeout\n",
    "graph_diameter = calculate_with_timeout(nx.diameter, largest_subgraph, timeout=20)\n",
    "print(\"Graph Diameter:\", graph_diameter)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d3cec2-e1a6-4452-ae5d-649a6ab2f758",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Your adjusted_graph\n",
    "adjusted_graph = largest_subgraph\n",
    "\n",
    "# Calculate centrality measures\n",
    "degree_centrality = nx.degree_centrality(adjusted_graph)\n",
    "betweenness_centrality = nx.betweenness_centrality(adjusted_graph)\n",
    "closeness_centrality = nx.closeness_centrality(adjusted_graph)\n",
    "eigenvector_centrality = nx.eigenvector_centrality(adjusted_graph)\n",
    "\n",
    "# Get centrality values for each node\n",
    "degree_values = np.array([degree_centrality[node] for node in adjusted_graph.nodes()])\n",
    "betweenness_values = np.array([betweenness_centrality[node] for node in adjusted_graph.nodes()])\n",
    "closeness_values = np.array([closeness_centrality[node] for node in adjusted_graph.nodes()])\n",
    "eigenvector_values = np.array([eigenvector_centrality[node] for node in adjusted_graph.nodes()])\n",
    "\n",
    "# Create scatter plots\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Degree vs Betweenness\n",
    "plt.subplot(321)\n",
    "plt.scatter(degree_values, betweenness_values, alpha=0.5)\n",
    "plt.xlabel(\"Degree Centrality\")\n",
    "plt.ylabel(\"Betweenness Centrality\")\n",
    "slope, intercept, r_value, p_value, std_err = linregress(degree_values, betweenness_values)\n",
    "plt.plot(degree_values, slope * degree_values + intercept, color='red')\n",
    "plt.title(f\"Degree vs Betweenness (R-squared = {r_value ** 2:.2f})\")\n",
    "\n",
    "# Degree vs Closeness\n",
    "plt.subplot(322)\n",
    "plt.scatter(degree_values, closeness_values, alpha=0.5)\n",
    "plt.xlabel(\"Degree Centrality\")\n",
    "plt.ylabel(\"Closeness Centrality\")\n",
    "slope, intercept, r_value, p_value, std_err = linregress(degree_values, closeness_values)\n",
    "plt.plot(degree_values, slope * degree_values + intercept, color='red')\n",
    "plt.title(f\"Degree vs Closeness (R-squared = {r_value ** 2:.2f})\")\n",
    "\n",
    "# Degree vs Eigenvector\n",
    "plt.subplot(323)\n",
    "plt.scatter(degree_values, eigenvector_values, alpha=0.5)\n",
    "plt.xlabel(\"Degree Centrality\")\n",
    "plt.ylabel(\"Eigenvector Centrality\")\n",
    "slope, intercept, r_value, p_value, std_err = linregress(degree_values, eigenvector_values)\n",
    "plt.plot(degree_values, slope * degree_values + intercept, color='red')\n",
    "plt.title(f\"Degree vs Eigenvector (R-squared = {r_value ** 2:.2f})\")\n",
    "\n",
    "# Betweenness vs Closeness\n",
    "plt.subplot(324)\n",
    "plt.scatter(betweenness_values, closeness_values, alpha=0.5)\n",
    "plt.xlabel(\"Betweenness Centrality\")\n",
    "plt.ylabel(\"Closeness Centrality\")\n",
    "slope, intercept, r_value, p_value, std_err = linregress(betweenness_values, closeness_values)\n",
    "plt.plot(betweenness_values, slope * betweenness_values + intercept, color='red')\n",
    "plt.title(f\"Betweenness vs Closeness (R-squared = {r_value ** 2:.2f})\")\n",
    "\n",
    "# Betweenness vs Eigenvector\n",
    "plt.subplot(325)\n",
    "plt.scatter(betweenness_values, eigenvector_values, alpha=0.5)\n",
    "plt.xlabel(\"Betweenness Centrality\")\n",
    "plt.ylabel(\"Eigenvector Centrality\")\n",
    "slope, intercept, r_value, p_value, std_err = linregress(betweenness_values, eigenvector_values)\n",
    "plt.plot(betweenness_values, slope * betweenness_values + intercept, color='red')\n",
    "plt.title(f\"Betweenness vs Eigenvector (R-squared = {r_value ** 2:.2f})\")\n",
    "\n",
    "# Closeness vs Eigenvector\n",
    "plt.subplot(326)\n",
    "plt.scatter(closeness_values, eigenvector_values, alpha=0.5)\n",
    "plt.xlabel(\"Closeness Centrality\")\n",
    "plt.ylabel(\"Eigenvector Centrality\")\n",
    "slope, intercept, r_value, p_value, std_err = linregress(closeness_values, eigenvector_values)\n",
    "plt.plot(closeness_values, slope * closeness_values + intercept, color='red')\n",
    "plt.title(f\"Closeness vs Eigenvector (R-squared = {r_value ** 2:.2f})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b46a6f3-99ec-443a-9b04-66121dedeb65",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import pandas as pd\n",
    "\n",
    "# Create a function to print the top nodes based on centrality values\n",
    "def print_top_nodes(centrality_dict, centrality_name, num_top_nodes=50):\n",
    "    sorted_nodes = sorted(centrality_dict, key=centrality_dict.get, reverse=True)\n",
    "    top_nodes = sorted_nodes[:num_top_nodes]\n",
    "    \n",
    "    print(f\"Top {num_top_nodes} nodes based on {centrality_name} centrality:\")\n",
    "    print(\"{:<10} {:<30} {:<20}\".format(\"Node\", \"Centrality Value\", \"Label\"))\n",
    "    print(\"=\"*60)\n",
    "    for node in top_nodes:\n",
    "        centrality_value = centrality_dict[node]\n",
    "        node_label = adjusted_graph.nodes[node]['properties']['name']\n",
    "        print(\"{:<10} {:<30} {:<20}\".format(node, centrality_value, node_label))\n",
    "\n",
    "# Print top nodes based on centrality measures\n",
    "print_top_nodes(eigenvector_centrality, \"Eigenvector\", num_top_nodes=50)\n",
    "print(\"\\n\")\n",
    "print_top_nodes(betweenness_centrality, \"Betweenness\", num_top_nodes=50)\n",
    "print(\"\\n\")\n",
    "print_top_nodes(closeness_centrality, \"Closeness\", num_top_nodes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4567f96-2f95-4f9f-878f-2e6dfd19d3c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a511b-61e5-4873-88ea-b033455ce1e2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf70b9-4159-4c26-98a2-f7380caa8eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424174a1-ea0c-4b87-b77f-97294e2f7b6a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026689da-3422-425e-abcc-51e7de6f4e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65abedfa-ec90-48fe-accf-d044d9725e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1VMwbMb37SH82f82izUUJ5l2xICkZlqFO",
     "timestamp": 1690975830068
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1f68be24f16f43198f50f7cc59950642": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e00d42a6a044326bd496c21e0f1974a",
       "IPY_MODEL_be803edef69b4aa7adfa595dd026aa73",
       "IPY_MODEL_e135d04476584e3aa73cf026434573f2"
      ],
      "layout": "IPY_MODEL_bf0a1397a0f74c019e3b53b803627316"
     }
    },
    "29b4ec4259d3482b851c0cffa4ab9069": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "729c6adc6baf4022a05d9619b6daa0c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e9149e073534b2b98fd2dcea8fc3ba0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "976bcaa193f84fd4bbba3e4c1b4672fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e00d42a6a044326bd496c21e0f1974a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf2efc07eb234305a835e8a746232b72",
      "placeholder": "",
      "style": "IPY_MODEL_976bcaa193f84fd4bbba3e4c1b4672fc",
      "value": "Remapping Christie&#x27;s data: 100%"
     }
    },
    "be803edef69b4aa7adfa595dd026aa73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c933ac28324e4133bc1b5e02460b5625",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_29b4ec4259d3482b851c0cffa4ab9069",
      "value": 3
     }
    },
    "bf0a1397a0f74c019e3b53b803627316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c933ac28324e4133bc1b5e02460b5625": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf2efc07eb234305a835e8a746232b72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e135d04476584e3aa73cf026434573f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_729c6adc6baf4022a05d9619b6daa0c0",
      "placeholder": "",
      "style": "IPY_MODEL_8e9149e073534b2b98fd2dcea8fc3ba0",
      "value": " 3/3 [00:00&lt;00:00, 58.40it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
